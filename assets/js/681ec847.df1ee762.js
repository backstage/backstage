/*! For license information please see 681ec847.df1ee762.js.LICENSE.txt */
"use strict";(self.webpackChunkbackstage_microsite=self.webpackChunkbackstage_microsite||[]).push([[965661],{376604:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>l});var a=t(474848),o=t(28453);const i={id:"external-integrations",title:"External integrations",description:"Documentation on External integrations to integrate systems with Backstage"},s=void 0,r={id:"features/software-catalog/external-integrations",title:"External integrations",description:"Documentation on External integrations to integrate systems with Backstage",source:"@site/../docs/features/software-catalog/external-integrations.md",sourceDirName:"features/software-catalog",slug:"/features/software-catalog/external-integrations",permalink:"/docs/next/features/software-catalog/external-integrations",draft:!1,unlisted:!1,editUrl:"https://github.com/backstage/backstage/edit/master/docs/features/software-catalog/external-integrations.md",tags:[],version:"current",frontMatter:{id:"external-integrations",title:"External integrations",description:"Documentation on External integrations to integrate systems with Backstage"},sidebar:"docs",previous:{title:"Extending the model",permalink:"/docs/next/features/software-catalog/extending-the-model"},next:{title:"Catalog Customization",permalink:"/docs/next/features/software-catalog/catalog-customization"}},c={},l=[{value:"Background",id:"background",level:2},{value:"Custom Entity Providers",id:"custom-entity-providers",level:2},{value:"Creating an Entity Provider",id:"creating-an-entity-provider",level:3},{value:"Provider Mutations",id:"provider-mutations",level:3},{value:"Installing the Provider",id:"installing-the-provider",level:3},{value:"New Backend System",id:"new-backend-system",level:4},{value:"Follow-up: Config Defined Schedule",id:"follow-up-config-defined-schedule",level:4},{value:"New Backend",id:"new-backend",level:4},{value:"Old Backend",id:"old-backend",level:4},{value:"Example User Entity Provider",id:"example-user-entity-provider",level:3},{value:"Custom Processors",id:"custom-processors",level:2},{value:"Processors and the Ingestion Loop",id:"processors-and-the-ingestion-loop",level:3},{value:"Deciding on the New Locations",id:"deciding-on-the-new-locations",level:3},{value:"Creating a Catalog Data Reader Processor",id:"creating-a-catalog-data-reader-processor",level:3},{value:"Installing Processor Using New Backend System",id:"installing-processor-using-new-backend-system",level:4},{value:"Caching processing results",id:"caching-processing-results",level:3},{value:"Supporting different metadata file formats",id:"supporting-different-metadata-file-formats",level:3},{value:"Using Custom Entity Data Parser with New Backend System",id:"using-custom-entity-data-parser-with-new-backend-system",level:4},{value:"Incremental Entity Provider",id:"incremental-entity-provider",level:2},{value:"Installation",id:"installation",level:3},{value:"Writing an Incremental Entity Provider",id:"writing-an-incremental-entity-provider",level:3},{value:"Installing the Incremental Entity Provider",id:"installing-the-incremental-entity-provider",level:3}];function d(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(n.p,{children:["Backstage natively supports importing catalog data through the use of\n",(0,a.jsx)(n.a,{href:"/docs/next/features/software-catalog/descriptor-format",children:"entity descriptor YAML files"}),". However, companies that\nalready have an existing system for keeping track of software and its owners can\nleverage those systems by integrating them with Backstage. This article shows\nthe two common ways of doing that integration: by adding a custom catalog\n",(0,a.jsx)(n.em,{children:"entity provider"}),", or by adding a ",(0,a.jsx)(n.em,{children:"processor"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"background",children:"Background"}),"\n",(0,a.jsxs)(n.p,{children:["The catalog has a frontend plugin part, that communicates via a service API to\nthe backend plugin part. The backend continuously ingests data from the sources\nyou specify, to store them in its database. The details of how this works is\ndetailed in ",(0,a.jsx)(n.a,{href:"/docs/next/features/software-catalog/life-of-an-entity",children:"The Life of an Entity"}),". Reading that article\nfirst is recommended."]}),"\n",(0,a.jsxs)(n.p,{children:["There are two main options for how to ingest data into the catalog: making a\n",(0,a.jsx)(n.a,{href:"#custom-entity-providers",children:"custom entity provider"}),", or making a\n",(0,a.jsx)(n.a,{href:"#custom-processors",children:"custom processor"}),". They both have strengths and drawbacks,\nbut the former would usually be preferred. Both options are presented in a\ndedicated subsection below."]}),"\n",(0,a.jsx)(n.h2,{id:"custom-entity-providers",children:"Custom Entity Providers"}),"\n",(0,a.jsx)(n.p,{children:"Entity providers sit at the very edge of the catalog. They are the original\nsources of entities that form roots of the processing tree. The dynamic location\nstore API, and the static locations you can specify in your app-config, are two\nexamples of builtin providers in the catalog."}),"\n",(0,a.jsx)(n.p,{children:"Some defining traits of entity providers:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"You instantiate them individually using code in your backend, and pass them to\nthe catalog builder. Often there's one provider instance per remote system."}),"\n",(0,a.jsx)(n.li,{children:"You may be responsible for actively running them. For example, some providers\nneed to be triggered periodically by a method call to know when they are meant\nto do their job; in that case you'll have to make that happen."}),"\n",(0,a.jsx)(n.li,{children:"The timing of their work is entirely detached from the processing loops. One\nprovider may run every 30 seconds, another one on every incoming webhook call\nof a certain type, etc."}),"\n",(0,a.jsx)(n.li,{children:"They can perform detailed updates on the set of entities that they are\nresponsible for. They can make full updates of the entire set, or issue\nindividual additions and removals."}),"\n",(0,a.jsx)(n.li,{children:"Their output is a set of unprocessed entities. Those are then subject to the\nprocessing loops before becoming final, stitched entities."}),"\n",(0,a.jsx)(n.li,{children:"When they remove an entity, the entire subtree of processor-generated entities\nunder that root is eagerly removed as well."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"creating-an-entity-provider",children:"Creating an Entity Provider"}),"\n",(0,a.jsxs)(n.p,{children:["The recommended way of instantiating the catalog backend classes is to use the ",(0,a.jsx)(n.code,{children:"CatalogBuilder"}),".\nWe will create a new\n",(0,a.jsx)(n.a,{href:"https://github.com/backstage/backstage/blob/master/plugins/catalog-node/src/api/provider.ts",children:(0,a.jsx)(n.code,{children:"EntityProvider"})}),"\nsubclass that can be added to this catalog builder."]}),"\n",(0,a.jsx)(n.p,{children:"Let's make a simple provider that can refresh a set of entities based on a\nremote store. The provider part of the interface is actually tiny - you only\nhave to supply a (unique) name, and accept a connection from the environment\nthrough which you can issue writes. The rest is up to the individual provider\nimplementation."}),"\n",(0,a.jsxs)(n.p,{children:["It is up to you where you put the code for this new provider class. For quick\nexperimentation you could place it in your backend package, but we recommend\nputting all extensions like this in a backend module package of their own in the\n",(0,a.jsx)(n.code,{children:"plugins"})," folder of your Backstage repo:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"yarn new --select backend-plugin-module --option pluginId=catalog\n"})}),"\n",(0,a.jsx)(n.p,{children:"The class will have this basic structure:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="plugins/catalog-backend-module-frobs/src/FrobsProvider.ts"',children:"import { Entity } from '@backstage/catalog-model';\nimport {\n  EntityProvider,\n  EntityProviderConnection,\n} from '@backstage/plugin-catalog-node';\nimport {\n  SchedulerServiceTaskRunner,\n  UrlReaderService,\n} from '@backstage/backend-plugin-api';\n\n/**\n * Provides entities from fictional frobs service.\n */\nexport class FrobsProvider implements EntityProvider {\n  private readonly env: string;\n  private readonly reader: UrlReaderService;\n  private connection?: EntityProviderConnection;\n  private taskRunner: SchedulerServiceTaskRunner;\n\n  /** [1] */\n  constructor(\n    env: string,\n    reader: UrlReaderService,\n    taskRunner: SchedulerServiceTaskRunner,\n  ) {\n    this.env = env;\n    this.reader = reader;\n    this.taskRunner = taskRunner;\n  }\n\n  /** [2] */\n  getProviderName(): string {\n    return `frobs-${this.env}`;\n  }\n\n  /** [3] */\n  async connect(connection: EntityProviderConnection): Promise<void> {\n    this.connection = connection;\n    await this.taskRunner.run({\n      id: this.getProviderName(),\n      fn: async () => {\n        await this.run();\n      },\n    });\n  }\n\n  /** [4] */\n  async run(): Promise<void> {\n    if (!this.connection) {\n      throw new Error('Not initialized');\n    }\n\n    const response = await this.reader.readUrl(\n      `https://frobs-${this.env}.example.com/data`,\n    );\n    const data = JSON.parse((await response.buffer()).toString());\n\n    /** [5] */\n    const entities: Entity[] = frobsToEntities(data);\n\n    /** [6] */\n    await this.connection.applyMutation({\n      type: 'full',\n      entities: entities.map(entity => ({\n        entity,\n        locationKey: `frobs-provider:${this.env}`,\n      })),\n    });\n  }\n}\n"})}),"\n",(0,a.jsx)(n.p,{children:"This class demonstrates several important concepts, some of which are optional.\nCheck out the numbered markings - let's go through them one by one."}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["The class takes an ",(0,a.jsx)(n.code,{children:"env"})," parameter. This is only illustrative for the sake of\nthe example. We'll use this field to exhibit the type of provider where end\nusers may want or need to make multiple instances of the same provider, and\nwhat the implications would be in that case."]}),"\n",(0,a.jsxs)(n.li,{children:["The catalog requires that all registered providers return a name that is\n",(0,a.jsx)(n.em,{children:"unique"})," among those providers, and which is ",(0,a.jsx)(n.em,{children:"stable"})," over time. The reason\nfor these requirements is, the emitted entities for each provider instance\nall hang around in a closed bucket of their own. This bucket needs to be tied\nto their provider over time, and across backend restarts. We'll see below how\nthe processor emits some entities and what that means for its own bucket."]}),"\n",(0,a.jsxs)(n.li,{children:["Once the catalog engine starts up, it immediately issues the ",(0,a.jsx)(n.code,{children:"connect"})," call\nto all known providers. This forms the bond between the code and the\ndatabase. This is also an opportunity for the provider to do one-time updates\non the connection at startup if it wants to."]}),"\n",(0,a.jsxs)(n.li,{children:["At this point the provider contract is already complete. But the class needs\nto do some actual work too! In this particular example, we chose to make a\n",(0,a.jsx)(n.code,{children:"run"})," method that has to be called each time that you want to issue a sync\nwith the ",(0,a.jsx)(n.code,{children:"frobs"})," service. Let's repeat that - this is only an example\nimplementation; some providers may be written in entirely different ways,\nsuch as for example subscribing to pubsub events and only reacting to those,\nor any number of other solutions. The only point is - external stimuli happen\nsomehow, which somehow get translated to calls on the ",(0,a.jsx)(n.code,{children:"connection"})," to persist\nthe outcome of that. This example issues a ",(0,a.jsx)(n.code,{children:"fetch"})," to the right service and\nissues a full refresh of its entity bucket based on that."]}),"\n",(0,a.jsxs)(n.li,{children:["The method translates the foreign data model to the native ",(0,a.jsx)(n.code,{children:"Entity"})," form, as\nexpected by the catalog. The ",(0,a.jsx)(n.code,{children:"Entity"})," must include the\n",(0,a.jsx)(n.code,{children:"backstage.io/managed-by-location"})," and\n",(0,a.jsx)(n.code,{children:"backstage.io/managed-by-origin-location annotations"}),"; otherwise, it will not\nappear in the Catalog and will generate warning logs. The\n",(0,a.jsx)(n.a,{href:"/docs/next/features/software-catalog/well-known-annotations#backstageiomanaged-by-location",children:"Well-known Annotations"}),"\ndocumentation has guidance on what values to use for these."]}),"\n",(0,a.jsxs)(n.li,{children:['Finally, we issue a "mutation" to the catalog. This persists the entities in\nour own bucket, along with an optional ',(0,a.jsx)(n.code,{children:"locationKey"})," that's used for conflict\nchecks. But this is a bigger topic - mutations warrant their own explanatory\nsection below."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"provider-mutations",children:"Provider Mutations"}),"\n",(0,a.jsx)(n.p,{children:"Let's circle back to the bucket analogy."}),"\n",(0,a.jsxs)(n.p,{children:["Each provider ",(0,a.jsx)(n.em,{children:"instance"}),' - not each class but each instance registered with the\ncatalog - has access to its own bucket of entities, and the bucket is identified\nby the stable name of the provider instance. Every time the provider issues\n"mutations", it changes the contents of that bucket. Nothing else outside of the\nbucket is accessible.']}),"\n",(0,a.jsx)(n.p,{children:"There are two different types of mutation."}),"\n",(0,a.jsxs)(n.p,{children:["The first is ",(0,a.jsx)(n.code,{children:"'full'"}),", which means to figuratively throw away the contents of\nthe bucket and replacing it with all the new contents specified. Under the\nhood, this is actually implemented through a highly efficient delta mechanism\nfor performance reasons, since it is common that the difference from one run to\nthe other is actually very small. This strategy is convenient for providers that\nhave easy access to batch-fetches of the entire subject material from a remote\nsource, and doesn't have access to, or does not want to compute, deltas."]}),"\n",(0,a.jsxs)(n.p,{children:["The other mutation type is ",(0,a.jsx)(n.code,{children:"'delta'"}),", which lets the provider explicitly upsert\nor delete entities in its bucket. This mutation is convenient e.g. for event\nbased providers, and can also be more performant since no deltas need to be\ncomputed, and previous bucket contents outside of the targeted set do not have\nto be taken into account."]}),"\n",(0,a.jsxs)(n.p,{children:["In all cases, the mutation entities are treated as ",(0,a.jsx)(n.em,{children:"unprocessed"})," entities. When\nthey land in the database, the registered catalog processors go to work on them\nto transform them into final, processed and stitched, entities ready for\nconsumption."]}),"\n",(0,a.jsxs)(n.p,{children:["Every entity emitted by a processor can have a ",(0,a.jsx)(n.code,{children:"locationKey"}),", as shown above.\nThis is a critical conflict resolution key, in the form of an opaque string that\nshould be unique for each location that an entity could be located at, and\nundefined if the entity does not have a fixed location."]}),"\n",(0,a.jsxs)(n.p,{children:["In practice it should be set to the serialized location reference if the entity\nis stored in Git, for example\n",(0,a.jsx)(n.code,{children:"https://github.com/backstage/backstage/blob/master/catalog-info.yaml"}),", or a\nsimilar string that distinctly pins down its origins. In our example we set it\nto a string that was distinct for the provider class, plus its instance\nidentifying properties which in this case was the ",(0,a.jsx)(n.code,{children:"env"}),"."]}),"\n",(0,a.jsx)(n.p,{children:'A conflict between two entity definitions happen when they have the same entity\nreference, i.e. kind, namespace, and name. In the event of a conflict, such as\nif two "competing" providers try to emit entities that have the same reference\ntriplet, the location key will be used according to the following rules to\nresolve the conflict:'}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"If the entity is already present in the database but does not have a location\nkey set, the new entity wins and will override the existing one."}),"\n",(0,a.jsx)(n.li,{children:"If the entity is already present in the database the new entity will only win\nif the location keys of the existing and new entity are the same."}),"\n",(0,a.jsx)(n.li,{children:"If the entity is not already present, insert the entity into the database\nalong with the provided location key."}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:'This may seem complex, but is a vital mechanism for ensuring that users aren\'t\npermitted to do "rogue" takeovers of already registered entities that belong to\nothers.'}),"\n",(0,a.jsx)(n.h3,{id:"installing-the-provider",children:"Installing the Provider"}),"\n",(0,a.jsxs)(n.p,{children:["You should now be able to add this class to your backend in\n",(0,a.jsx)(n.code,{children:"packages/backend/src/plugins/catalog.ts"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/plugins/catalog.ts"',children:"/* highlight-add-next-line */\nimport { FrobsProvider } from '../path/to/class';\n\nexport default async function createPlugin(\n  env: PluginEnvironment,\n): Promise<Router> {\n  const builder = CatalogBuilder.create(env);\n  /* highlight-add-start */\n  const taskRunner = env.scheduler.createScheduledTaskRunner({\n    frequency: { minutes: 30 },\n    timeout: { minutes: 10 },\n  });\n  const frobs = new FrobsProvider('production', env.reader, taskRunner);\n  builder.addEntityProvider(frobs);\n  /* highlight-add-end */\n\n  const { processingEngine, router } = await builder.build();\n  await processingEngine.start();\n\n  // ..\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Note that we used the builtin scheduler facility to regularly call the ",(0,a.jsx)(n.code,{children:"run"}),"\nmethod of the provider, in this example. It is a suitable driver for this\nparticular type of recurring task. We placed the scheduling after the actual\nconstruction and startup phase of the rest of the catalog, because at that point\nthe ",(0,a.jsx)(n.code,{children:"connect"})," call has been made to the provider."]}),"\n",(0,a.jsx)(n.p,{children:"Start up the backend - it should now start reading from the previously\nregistered location and you'll see your entities start to appear in Backstage."}),"\n",(0,a.jsx)(n.h4,{id:"new-backend-system",children:"New Backend System"}),"\n",(0,a.jsx)(n.p,{children:"To install the provider using the new backend system you will need to create a module and add it to your backend. The following is a very simplified example of what that would look like:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/index.ts"',children:"import { createBackend } from '@backstage/backend-defaults';\nimport {\n  coreServices,\n  createBackendModule,\n} from '@backstage/backend-plugin-api';\nimport { catalogProcessingExtensionPoint } from '@backstage/plugin-catalog-node/alpha';\nimport { FrobsProvider } from './path/to/class';\n\nexport const catalogModuleFrobsProvider = createBackendModule({\n  pluginId: 'catalog',\n  moduleId: 'frobs-provider',\n  register(env) {\n    env.registerInit({\n      deps: {\n        catalog: catalogProcessingExtensionPoint,\n        reader: coreServices.urlReader,\n        /* highlight-add-start */\n        scheduler: coreServices.scheduler,\n        /* highlight-add-end */\n      },\n      async init({ catalog, reader, scheduler }) {\n        const taskRunner = scheduler.createScheduledTaskRunner({\n          frequency: { minutes: 30 },\n          timeout: { minutes: 10 },\n        });\n        const frobs = new FrobsProvider('dev', reader, taskRunner);\n        catalog.addEntityProvider(frobs);\n      },\n    });\n  },\n});\n\nconst backend = createBackend();\n\nbackend.add(import('@backstage/plugin-catalog-backend'));\nbackend.add(catalogModuleFrobsProvider);\n\n// Other plugins ...\n\nbackend.start();\n"})}),"\n",(0,a.jsx)(n.h4,{id:"follow-up-config-defined-schedule",children:"Follow-up: Config Defined Schedule"}),"\n",(0,a.jsxs)(n.p,{children:["If you want to go a step further and increase the configurability of your new ",(0,a.jsx)(n.code,{children:"FrobsProvider"}),", you can define the schedule that the task runs at in ",(0,a.jsx)(n.code,{children:"app-config.yaml"})," instead of requiring code changes to adjust."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",metastring:'title="app-config.yaml"',children:"catalog:\n  providers:\n    frobs-provider:\n      schedule:\n        initialDelay: { seconds: 30 }\n        frequency: { hours: 1 }\n        timeout: { minutes: 50 }\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This approach will also allow you to customize the schedule per environment. You can also ",(0,a.jsx)(n.a,{href:"/docs/next/conf/defining",children:"add a schema to your config"}),"."]}),"\n",(0,a.jsx)(n.h4,{id:"new-backend",children:"New Backend"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/index.ts"',children:"import {\n  SchedulerServiceTaskScheduleDefinition,\n  /* highlight-add-start */\n  readSchedulerServiceTaskScheduleDefinitionFromConfig,\n  /* highlight-add-end */\n} from '@backstage/backend-plugin-api';\n\nexport const catalogModuleFrobsProvider = createBackendModule({\n  pluginId: 'catalog',\n  moduleId: 'frobs-provider',\n  register(env) {\n    env.registerInit({\n      deps: {\n        // ... other deps\n        /* highlight-add-start */\n        rootConfig: coreServices.rootConfig,\n        /* highlight-add-end */\n      },\n      async init({ catalog, reader, scheduler, rootConfig }) {\n        /* highlight-add-start */\n        const config = rootConfig.getConfig('catalog.providers.frobs-provider'); // Generally, catalog config goes under catalog.providers.pluginId\n        // Add a default schedule if you don't define one in config.\n        const schedule = config.has('schedule')\n          ? readSchedulerServiceTaskScheduleDefinitionFromConfig(\n              config.getConfig('schedule'),\n            )\n          : {\n              frequency: { minutes: 30 },\n              timeout: { minutes: 10 },\n            };\n        const taskRunner: SchedulerServiceTaskRunner =\n          scheduler.createScheduledTaskRunner(schedule);\n        /* highlight-add-end */\n\n        // rest of your code\n      },\n    });\n  },\n});\n"})}),"\n",(0,a.jsx)(n.h4,{id:"old-backend",children:"Old Backend"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/plugins/catalog.ts"',children:"/* highlight-add-next-line */\nimport { FrobsProvider } from '../path/to/class';\nimport {\n  /* highlight-add-start */\n  readSchedulerServiceTaskScheduleDefinitionFromConfig,\n  /* highlight-add-end */\n} from '@backstage/backend-plugin-api';\n\nexport default async function createPlugin(\n  env: PluginEnvironment,\n): Promise<Router> {\n  /* highlight-add-start */\n  const config = env.config.getConfig('catalog.providers.frobs-provider'); // Generally, catalog config goes under catalog.providers.pluginId\n  // Add a default schedule if you don't define one in config.\n  const schedule = config.has('schedule')\n    ? readSchedulerServiceTaskScheduleDefinitionFromConfig(\n        config.getConfig('schedule'),\n      )\n    : {\n        frequency: { minutes: 30 },\n        timeout: { minutes: 10 },\n      };\n  const taskRunner = env.scheduler.createScheduledTaskRunner(schedule);\n  /* highlight-add-end */\n\n  // ..\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"example-user-entity-provider",children:"Example User Entity Provider"}),"\n",(0,a.jsx)(n.p,{children:"If you have a 3rd party entity provider such as an internal HR system that you wish to use you are not limited to using our entity providers, (or simply wish to add to existing entity providers with your own data)."}),"\n",(0,a.jsx)(n.p,{children:"We can create an entity provider to read entities that are based off that provider."}),"\n",(0,a.jsxs)(n.p,{children:["We create a basic entity provider as shown above. In the example below we might want to extract our users from an HR system, I am assuming the HR system already has the slackUserId to get that information please see the ",(0,a.jsx)(n.a,{href:"https://api.slack.com/methods",children:"Slack Api"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import {\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n} from '@backstage/catalog-model';\nimport {\n  EntityProvider,\n  EntityProviderConnection,\n} from '@backstage/plugin-catalog-backend';\nimport { WebClient } from '@slack/web-api';\nimport { kebabCase } from 'lodash';\n\ninterface Staff {\n  displayName: string;\n  slackUserId: string;\n  jobTitle: string;\n  photoUrl: string;\n  address: string;\n  email: string;\n}\n\nexport class UserEntityProvider implements EntityProvider {\n  private readonly getStaffUrl: string;\n  protected readonly slackTeam: string;\n  protected readonly slackToken: string;\n  protected connection?: EntityProviderConnection;\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const getStaffUrl = config.getString('staff.url');\n    const slackToken = config.getString('slack.token');\n    const slackTeam = config.getString('slack.team');\n    return new UserEntityProvider({\n      ...options,\n      getStaffUrl,\n      slackToken,\n      slackTeam,\n    });\n  }\n\n  private constructor(options: {\n    getStaffUrl: string;\n    slackToken: string;\n    slackTeam: string;\n  }) {\n    this.getStaffUrl = options.getStaffUrl;\n    this.slackToken = options.slackToken;\n    this.slackTeam = options.slackTeam;\n  }\n\n  async getAllStaff(): Promise<Staff[]> {\n    return await axios.get(this.getStaffUrl);\n  }\n\n  public async connect(connection: EntityProviderConnection): Promise<void> {\n    this.connection = connection;\n  }\n\n  async run(): Promise<void> {\n    if (!this.connection) {\n      throw new Error('User Connection Not initialized');\n    }\n\n    const userResources: UserEntity[] = [];\n    const staff = await this.getAllStaff();\n\n    for (const user of staff) {\n      // we can add any links here in this case it would be adding a slack link to the users so you can directly slack them.\n      const links =\n        user.slackUserId != null && user.slackUserId.length > 0\n          ? [\n              {\n                url: `slack://user?team=${this.slackTeam}&id=${user.slackUserId}`,\n                title: 'Slack',\n                icon: 'message',\n              },\n            ]\n          : undefined;\n      const userEntity: UserEntity = {\n        kind: 'User',\n        apiVersion: 'backstage.io/v1alpha1',\n        metadata: {\n          annotations: {\n            [ANNOTATION_LOCATION]: 'hr-user-https://www.hrurl.com/',\n            [ANNOTATION_ORIGIN_LOCATION]: 'hr-user-https://www.hrurl.com/',\n          },\n          links,\n          // name of the entity\n          name: kebabCase(user.displayName),\n          // name for display purposes could be anything including email\n          title: user.displayName,\n        },\n        spec: {\n          profile: {\n            displayName: user.displayName,\n            email: user.email,\n            picture: user.photoUrl,\n          },\n          memberOf: [],\n        },\n      };\n\n      userResources.push(userEntity);\n    }\n\n    await this.connection.applyMutation({\n      type: 'full',\n      entities: userResources.map(entity => ({\n        entity,\n        locationKey: 'hr-user-https://www.hrurl.com/',\n      })),\n    });\n  }\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"custom-processors",children:"Custom Processors"}),"\n",(0,a.jsx)(n.p,{children:"The other possible way of ingesting data into the catalog is through the use of\nlocation reading catalog processors."}),"\n",(0,a.jsx)(n.p,{children:"Processors sit in the middle of the processing loops of the catalog. They are\nresponsible for updating and finalizing unprocessed entities on their way to\nbecoming final, stitched entities. They can also, crucially, emit other entities\nwhile doing so. Those then form branches of the entity tree."}),"\n",(0,a.jsx)(n.p,{children:"Some defining traits of processors:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"You instantiate them using code in your backend, and pass them to the catalog\nbuilder. There's usually only one instance of each type, which then gets\ncalled many times over in parallel for all entities in the catalog."}),"\n",(0,a.jsx)(n.li,{children:"Their invocation is driven by the fixed processing loop. All processors are\nunconditionally repeatedly called for all entities. You cannot control this\nbehavior, besides adjusting the frequency of the loop, which then applies\nequally to all processors."}),"\n",(0,a.jsx)(n.li,{children:"They cannot control in detail the entities that they emit, the only effective\noperation is upsert on their children. If they stop emitting a certain child,\nthat child becomes marked as an orphan; no deletions are possible."}),"\n",(0,a.jsx)(n.li,{children:"Their input is an unprocessed entity, and their output is modifications to\nthat same entity plus possibly some auxiliary data including unprocessed child\nentities."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"processors-and-the-ingestion-loop",children:"Processors and the Ingestion Loop"}),"\n",(0,a.jsxs)(n.p,{children:["The catalog holds a number of registered locations, that were added either by\nsite admins or by individual Backstage users. Their purpose is to reference some\nsort of data that the catalog shall keep itself up to date with. Each location\nhas a ",(0,a.jsx)(n.code,{children:"type"}),", and a ",(0,a.jsx)(n.code,{children:"target"})," that are both strings."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# Example location\ntype: url\ntarget: https://github.com/backstage/backstage/blob/master/catalog-info.yaml\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The builtin catalog backend has an ingestion loop that periodically goes through\nall of these registered locations, and pushes them and their resulting output\nthrough the list of ",(0,a.jsx)(n.em,{children:"processors"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"Processors are classes that the site admin has registered with the catalog at\nstartup. They are at the heart of all catalog logic, and have the ability to\nread the contents of locations, modify in-flight entities that were read out of\na location, perform validation, and more. The catalog comes with a set of\nbuiltin processors, that have the ability to read from a list of well known\nlocation types, to perform the basic processing needs, etc., but more can be\nadded by the organization that adopts Backstage."}),"\n",(0,a.jsx)(n.p,{children:"We will now show the process of creating a new processor and location type,\nwhich enables the ingestion of catalog data from an existing external API."}),"\n",(0,a.jsx)(n.h3,{id:"deciding-on-the-new-locations",children:"Deciding on the New Locations"}),"\n",(0,a.jsx)(n.p,{children:"The first step is to decide how we want to point at the system that holds our\ndata. Let's assume that it is internally named System-X and can be reached\nthrough HTTP REST calls to its API."}),"\n",(0,a.jsx)(n.p,{children:"Let's decide that our locations shall take the following form:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"type: system-x\ntarget: http://systemx.services.example.net/api/v2\n"})}),"\n",(0,a.jsxs)(n.p,{children:["It got its own made-up ",(0,a.jsx)(n.code,{children:"type"}),", and the ",(0,a.jsx)(n.code,{children:"target"})," conveniently points to the\nactual API endpoint to talk to."]}),"\n",(0,a.jsx)(n.p,{children:"So now we have to make the catalog aware of such a location so that it can start\nfeeding it into the ingestion loop. For this kind of an integration, you'd\ntypically want to add it to the list of statically always-available locations in\nthe config."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",metastring:'title="app-config.yaml"',children:"catalog:\n  locations:\n    - type: system-x\n      target: http://systemx.services.example.net/api/v2\n"})}),"\n",(0,a.jsx)(n.p,{children:"If you start up the backend now, it will start to periodically say that it could\nnot find a processor that supports that location. So let's make a processor that\ndoes so!"}),"\n",(0,a.jsx)(n.h3,{id:"creating-a-catalog-data-reader-processor",children:"Creating a Catalog Data Reader Processor"}),"\n",(0,a.jsxs)(n.p,{children:["The recommended way of instantiating the catalog backend classes is to use the ",(0,a.jsx)(n.code,{children:"CatalogBuilder"}),".\nWe will create a new\n",(0,a.jsx)(n.a,{href:"https://github.com/backstage/backstage/blob/master/plugins/catalog-node/src/api/processor.ts",children:(0,a.jsx)(n.code,{children:"CatalogProcessor"})}),"\nsubclass that can be added to this catalog builder."]}),"\n",(0,a.jsxs)(n.p,{children:["It is up to you where you put the code for this new processor class. For quick\nexperimentation you could place it in your backend package, but we recommend\nputting all extensions like this in a backend module package of their own in the\n",(0,a.jsx)(n.code,{children:"plugins"})," folder of your Backstage repo:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"yarn new --select backend-module --option pluginId=catalog\n"})}),"\n",(0,a.jsx)(n.p,{children:"The class will have this basic structure:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"import {\n  processingResult,\n  CatalogProcessor,\n  CatalogProcessorEmit,\n} from '@backstage/plugin-catalog-node';\nimport { UrlReaderService } from '@backstage/backend-plugin-api';\n\nimport { LocationSpec } from '@backstage/plugin-catalog-common';\n\n// A processor that reads from the fictional System-X\nexport class SystemXReaderProcessor implements CatalogProcessor {\n  constructor(private readonly reader: UrlReaderService) {}\n\n  getProcessorName(): string {\n    return 'SystemXReaderProcessor';\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    // Pick a custom location type string. A location will be\n    // registered later with this type.\n    if (location.type !== 'system-x') {\n      return false;\n    }\n\n    try {\n      // Use the builtin reader facility to grab data from the\n      // API. If you prefer, you can just use plain fetch here,\n      // or any other method of your choosing.\n      const response = await this.reader.readUrl(location.target);\n      const json = JSON.parse((await response.buffer()).toString());\n      // Repeatedly call emit(processingResult.entity(location, <entity>))\n    } catch (error) {\n      const message = `Unable to read ${location.type}, ${error}`;\n      emit(processingResult.generalError(location, message));\n    }\n\n    return true;\n  }\n}\n"})}),"\n",(0,a.jsx)(n.p,{children:"The key points to note are:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Make a class that implements ",(0,a.jsx)(n.code,{children:"CatalogProcessor"})]}),"\n",(0,a.jsxs)(n.li,{children:["Only act on location types that you care about, and leave the rest alone by\nreturning ",(0,a.jsx)(n.code,{children:"false"})]}),"\n",(0,a.jsxs)(n.li,{children:["Read the data from the external system in any way you see fit. Use the\nlocation ",(0,a.jsx)(n.code,{children:"target"})," field if you designed it as mentioned above"]}),"\n",(0,a.jsxs)(n.li,{children:["Call ",(0,a.jsx)(n.code,{children:"emit"})," any number of times with the results of that process"]}),"\n",(0,a.jsxs)(n.li,{children:["Finally return ",(0,a.jsx)(n.code,{children:"true"})]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["You should now be able to add this class to your backend in\n",(0,a.jsx)(n.code,{children:"packages/backend/src/plugins/catalog.ts"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/plugins/catalog.ts"',children:"/* highlight-add-next-line */\nimport { SystemXReaderProcessor } from '../path/to/class';\n\nexport default async function createPlugin(\n  env: PluginEnvironment,\n): Promise<Router> {\n  const builder = CatalogBuilder.create(env);\n  /* highlight-add-next-line */\n  builder.addProcessor(new SystemXReaderProcessor(env.reader));\n\n  // ..\n}\n"})}),"\n",(0,a.jsx)(n.p,{children:"Start up the backend - it should now start reading from the previously\nregistered location and you'll see your entities start to appear in Backstage."}),"\n",(0,a.jsx)(n.h4,{id:"installing-processor-using-new-backend-system",children:"Installing Processor Using New Backend System"}),"\n",(0,a.jsx)(n.p,{children:"To install the processor using the new backend system you will need to create a module and add it to your backend. The following is a very simplified example of what that would look like:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/index.ts"',children:"import { createBackend } from '@backstage/backend-defaults';\nimport {\n  coreServices,\n  createBackendModule,\n} from '@backstage/backend-plugin-api';\nimport { catalogProcessingExtensionPoint } from '@backstage/plugin-catalog-node/alpha';\nimport { SystemXReaderProcessor } from '../path/to/class';\n\nexport const catalogModuleSystemXReaderProcessor = createBackendModule({\n  pluginId: 'catalog',\n  moduleId: 'system-x-reader-processor',\n  register(env) {\n    env.registerInit({\n      deps: {\n        catalog: catalogProcessingExtensionPoint,\n        reader: coreServices.urlReader,\n      },\n      async init({ catalog, reader }) {\n        catalog.addProcessor(new SystemXReaderProcessor(reader));\n      },\n    });\n  },\n});\n\nconst backend = createBackend();\n\nbackend.add(import('@backstage/plugin-catalog-backend'));\nbackend.add(catalogModuleSystemXReaderProcessor);\n\n// Other plugins ...\n\nbackend.start();\n"})}),"\n",(0,a.jsx)(n.h3,{id:"caching-processing-results",children:"Caching processing results"}),"\n",(0,a.jsx)(n.p,{children:"The catalog periodically refreshes entities in the catalog, and in doing so it\ncalls out to external systems to fetch changes. This can be taxing for upstream\nservices and large deployments may get rate limited if too many requests are\nsent. Luckily many external systems provide ETag support to check for changes\nwhich usually doesn't count towards the quota and saves resources both\ninternally and externally."}),"\n",(0,a.jsxs)(n.p,{children:["The catalog has built in support for leveraging ",(0,a.jsx)(n.code,{children:"ETag"}),"s when refreshing external\nlocations in GitHub. This example aims to demonstrate how to add the same\nbehavior for ",(0,a.jsx)(n.code,{children:"system-x"})," that we implemented earlier."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"import { Entity } from '@backstage/catalog-model';\nimport { UrlReaderService } from '@backstage/backend-plugin-api';\nimport {\n  processingResult,\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  CatalogProcessorCache,\n  CatalogProcessorParser,\n  LocationSpec,\n} from '@backstage/plugin-catalog-node';\n\n// It's recommended to always bump the CACHE_KEY version if you make\n// changes to the processor implementation or CacheItem.\nconst CACHE_KEY = 'v1';\n\n// Our cache item contains the ETag used in the upstream request\n// as well as the processing result used when the Etag matches.\n// Bump the CACHE_KEY version if you make any changes to this type.\ntype CacheItem = {\n  etag: string;\n  entity: Entity;\n};\n\nexport class SystemXReaderProcessor implements CatalogProcessor {\n  constructor(private readonly reader: UrlReaderService) {}\n\n  getProcessorName() {\n    // The processor name must be unique.\n    return 'system-x-processor';\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n    _parser: CatalogProcessorParser,\n    cache: CatalogProcessorCache,\n  ): Promise<boolean> {\n    // Pick a custom location type string. A location will be\n    // registered later with this type.\n    if (location.type !== 'system-x') {\n      return false;\n    }\n    const cacheItem = await cache.get<CacheItem>(CACHE_KEY);\n    try {\n      // This assumes an URL reader that returns the response together with the ETag.\n      // We send the ETag from the previous run if it exists.\n      // The previous ETag will be set in the headers for the outgoing request and system-x\n      // is going to throw NOT_MODIFIED (HTTP 304) if the ETag matches.\n      const response = await this.reader.readUrl(location.target, {\n        etag: cacheItem?.etag,\n      });\n      if (!response) {\n        // readUrl is currently optional to implement so we have to check if we get a response back.\n        throw new Error(\n          'No URL reader that can parse system-x targets installed',\n        );\n      }\n\n      // ETag is optional in the response but we need it to cache the result.\n      if (!response.etag) {\n        throw new Error(\n          'No ETag returned from system-x, cannot use response for caching',\n        );\n      }\n\n      // For this example the JSON payload is a single entity.\n      const entity: Entity = JSON.parse((await response.buffer()).toString());\n      emit(processingResult.entity(location, entity));\n\n      // Update the cache with the new ETag and entity used for the next run.\n      await cache.set<CacheItem>(CACHE_KEY, {\n        etag: response.etag,\n        entity,\n      });\n    } catch (error) {\n      if (error.name === 'NotModifiedError' && cacheItem) {\n        // The ETag matches and we have a cached value from the previous run.\n        emit(processingResult.entity(location, cacheItem.entity));\n      } else {\n        const message = `Unable to read ${location.type}, ${error}`;\n        emit(processingResult.generalError(location, message));\n      }\n    }\n\n    return true;\n  }\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"supporting-different-metadata-file-formats",children:"Supporting different metadata file formats"}),"\n",(0,a.jsxs)(n.p,{children:["Sometimes you might already have files in GitHub or some provider that Backstage already supports but the metadata format that you use is not the same as ",(0,a.jsx)(n.code,{children:"catalog-info.yaml"})," files. In this case you can implement a custom parser that can read the files and convert them on-the-fly to the ",(0,a.jsx)(n.code,{children:"Entity"})," format that Backstage expects, and it will integrate seamlessly into Catalog so that you can use things like the ",(0,a.jsx)(n.code,{children:"GithubEntityProvider"})," to read these files."]}),"\n",(0,a.jsxs)(n.p,{children:["What you will need to do is to provide a custom ",(0,a.jsx)(n.code,{children:"CatalogProcessorParser"})," and provide that to ",(0,a.jsx)(n.code,{children:"builder.setEntityDataParser"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"Let's say my format looks something like this:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"id: my-service\ntype: service\nauthor: user@backstage.com\n"})}),"\n",(0,a.jsxs)(n.p,{children:["We need to build a custom parser that can read this format and convert it to the ",(0,a.jsx)(n.code,{children:"Entity"})," format that Backstage expects."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/lib/customEntityDataParser.ts"',children:"import {\n  CatalogProcessorParser,\n  CatalogProcessorResult,\n  LocationSpec,\n  processingResult,\n} from '@backstage/plugin-catalog-node';\nimport yaml from 'yaml';\nimport {\n  Entity,\n  stringifyLocationRef,\n  ANNOTATION_ORIGIN_LOCATION,\n  ANNOTATION_LOCATION,\n} from '@backstage/catalog-model';\nimport _ from 'lodash';\nimport parseGitUrl from 'git-url-parse';\n\n// This implementation will map whatever your own format is into valid Entity objects.\nconst makeEntityFromCustomFormatJson = (\n  component: { id: string; type: string; author: string },\n  location: LocationSpec,\n): Entity => {\n  return {\n    apiVersion: 'backstage.io/v1alpha1',\n    kind: 'Component',\n    metadata: {\n      name: component.id,\n      namespace: 'default',\n      annotations: {\n        [ANNOTATION_LOCATION]: `${location.type}:${location.target}`,\n        [ANNOTATION_ORIGIN_LOCATION]: `${location.type}:${location.target}`,\n      },\n    },\n    spec: {\n      type: component.type,\n      owner: component.author,\n      lifecycle: 'experimental',\n    },\n  };\n};\n\nexport const customEntityDataParser: CatalogProcessorParser = async function* ({\n  data,\n  location,\n}) {\n  let documents: yaml.Document.Parsed[];\n  try {\n    // let's treat the incoming file always as yaml, you can of course change this if your format is not yaml.\n    documents = yaml.parseAllDocuments(data.toString('utf8')).filter(d => d);\n  } catch (e) {\n    // if we failed to parse as yaml throw some errors.\n    const loc = stringifyLocationRef(location);\n    const message = `Failed to parse YAML at ${loc}, ${e}`;\n    yield processingResult.generalError(location, message);\n    return;\n  }\n\n  for (const document of documents) {\n    // If there's errors parsing the document as yaml, we should throw an error.\n    if (document.errors?.length) {\n      const loc = stringifyLocationRef(location);\n      const message = `YAML error at ${loc}, ${document.errors[0]}`;\n      yield processingResult.generalError(location, message);\n    } else {\n      // Convert the document to JSON\n      const json = document.toJSON();\n      if (_.isPlainObject(json)) {\n        // Is this a catalog-info.yaml file?\n        if (json.apiVersion) {\n          yield processingResult.entity(location, json as Entity);\n        } else {\n          // let's treat this like it's our custom format instead.\n          yield processingResult.entity(\n            location,\n            makeEntityFromCustomFormatJson(json, location),\n          );\n        }\n      } else if (json === null) {\n        // Ignore null values, these happen if there is an empty document in the\n        // YAML file, for example if --- is added to the end of the file.\n      } else {\n        // We don't support this format.\n        const message = `Expected object at root, got ${typeof json}`;\n        yield processingResult.generalError(location, message);\n      }\n    }\n  }\n};\n"})}),"\n",(0,a.jsx)(n.p,{children:"This is a lot of code right now, as this is a pretty niche use-case, so we don't currently provide many helpers for you to be able to provide custom implementations easier or to compose together different parsers."}),"\n",(0,a.jsxs)(n.p,{children:["You then should be able to provide this ",(0,a.jsx)(n.code,{children:"customEntityDataParser"})," to the ",(0,a.jsx)(n.code,{children:"CatalogBuilder"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/plugins/catalog.ts"',children:"import { customEntityDataParser } from '../lib/customEntityDataParser';\n\n...\n\nbuilder.setEntityDataParser(customEntityDataParser);\n"})}),"\n",(0,a.jsx)(n.h4,{id:"using-custom-entity-data-parser-with-new-backend-system",children:"Using Custom Entity Data Parser with New Backend System"}),"\n",(0,a.jsx)(n.p,{children:"To use a custom entity data parse with the new backend system you will need to create a module and add it to your backend. The following is a very simplified example of what that would look like:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/index.ts"',children:"import { createBackend } from '@backstage/backend-defaults';\nimport {\n  coreServices,\n  createBackendModule,\n} from '@backstage/backend-plugin-api';\nimport { catalogModelExtensionPoint } from '@backstage/plugin-catalog-node/alpha';\nimport { customEntityDataParser } from '../lib/customEntityDataParser';\n\nexport const catalogModuleCustomDataParser = createBackendModule({\n  pluginId: 'catalog',\n  moduleId: 'custom-data-parser',\n  register(env) {\n    env.registerInit({\n      deps: {\n        catalog: catalogModelExtensionPoint,\n        reader: coreServices.urlReader,\n      },\n      async init({ catalog, reader }) {\n        catalog.setEntityDataParser(customEntityDataParser);\n      },\n    });\n  },\n});\n\nconst backend = createBackend();\n\nbackend.add(import('@backstage/plugin-catalog-backend'));\nbackend.add(catalogModuleCustomDataParser);\n\n// Other plugins ...\n\nbackend.start();\n"})}),"\n",(0,a.jsx)(n.h2,{id:"incremental-entity-provider",children:"Incremental Entity Provider"}),"\n",(0,a.jsx)(n.p,{children:"For large data sources that may not fit into memory but support pagination, the Incremental Entity Provider offers an efficient way to ingest data incrementally, handling deletions and updates seamlessly while minimizing memory usage."}),"\n",(0,a.jsxs)(n.p,{children:["You can find more details about ",(0,a.jsx)(n.a,{href:"https://github.com/backstage/backstage/tree/master/plugins/catalog-backend-module-incremental-ingestion#why-did-we-create-it",children:"why it was created"})," and its ",(0,a.jsx)(n.a,{href:"https://github.com/backstage/backstage/tree/master/plugins/catalog-backend-module-incremental-ingestion#requirements",children:"requirements"}),"."]}),"\n",(0,a.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Install ",(0,a.jsx)(n.code,{children:"@backstage/plugin-catalog-backend-module-incremental-ingestion"})," with ",(0,a.jsx)(n.code,{children:"yarn --cwd packages/backend add @backstage/plugin-catalog-backend-module-incremental-ingestion"})," from the Backstage root directory."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Add the following code to the ",(0,a.jsx)(n.code,{children:"packages/backend/src/index.ts"})," file:"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/index.ts"',children:"const backend = createBackend();\n\n/* highlight-add-start */\nbackend.add(\n  import(\n    '@backstage/plugin-catalog-backend-module-incremental-ingestion/alpha'\n  ),\n);\n/* highlight-add-end */\n\nbackend.start();\n"})}),"\n",(0,a.jsx)(n.h3,{id:"writing-an-incremental-entity-provider",children:"Writing an Incremental Entity Provider"}),"\n",(0,a.jsxs)(n.p,{children:["To create an Incremental Entity Provider, you need to know how to retrieve a single page of data from an API with pagination. The ",(0,a.jsx)(n.code,{children:"IncrementalEntityProvider"})," facilitates this by requiring:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"getProviderName:"})," A unique name to avoid conflicts with other providers."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"next:"})," Fetches a specific page of entities, moving the cursor forward."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"around:"})," Handles setup and tear-down, wrapping the process that iterates through multiple pages."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["For more information on compatibility, refer to the ",(0,a.jsx)(n.a,{href:"https://github.com/backstage/backstage/tree/master/plugins/catalog-backend-module-incremental-ingestion#requirements",children:"requirements"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"In this tutorial, we'll implement an Incremental Entity Provider that interacts with an imaginary API to fetch a list of imaginary services."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"interface MyApiClient {\n  getServices(page: number): MyPaginatedResults<Service>;\n}\n\ninterface MyPaginatedResults<T> {\n  items: T[];\n  totalPages: number;\n}\n\ninterface Service {\n  name: string;\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:["These are the only 3 methods that you need to implement. ",(0,a.jsx)(n.code,{children:"getProviderName()"})," is pretty self-explanatory and it's identical to the ",(0,a.jsx)(n.code,{children:"getProviderName()"})," method on a regular Entity Provider."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"import { IncrementalEntityProvider } from '@backstage/plugin-catalog-backend-module-incremental-ingestion';\n\n// This will include your pagination information, let's say our API accepts a `page` parameter.\n// In this case, the cursor will include `page`\ninterface Cursor {\n  page: number;\n}\n\n// This interface describes the type of data that will be passed to your burst function.\ninterface Context {\n  apiClient: MyApiClient;\n}\n\nexport class MyIncrementalEntityProvider\n  implements IncrementalEntityProvider<Cursor, Context>\n{\n  getProviderName() {\n    return `MyIncrementalEntityProvider`;\n  }\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"around"})," method is used for setup and tear-down. For example, if you need to create a client that will connect to the API, you would do that here."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"export class MyIncrementalEntityProvider\n  implements IncrementalEntityProvider<Cursor, Context>\n{\n  getProviderName() {\n    return `MyIncrementalEntityProvider`;\n  }\n\n  async around(burst: (context: Context) => Promise<void>): Promise<void> {\n    const apiClient = new MyApiClient();\n\n    await burst({ apiClient });\n\n    // If you need to do any teardown, you can do it here.\n  }\n}\n"})}),"\n",(0,a.jsx)(n.p,{children:"If you need to pass a token to your API, then you can create a constructor that will receive a token and use the token to setup the client."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"export class MyIncrementalEntityProvider\n  implements IncrementalEntityProvider<Cursor, Context>\n{\n  private readonly token: string;\n\n  constructor(token: string) {\n    this.token = token;\n  }\n\n  getProviderName() {\n    return `MyIncrementalEntityProvider`;\n  }\n\n  async around(burst: (context: Context) => Promise<void>): Promise<void> {\n    const apiClient = new MyApiClient(this.token);\n\n    await burst({ apiClient });\n  }\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The last step is to implement the actual ",(0,a.jsx)(n.code,{children:"next"})," method that will accept the cursor, call the API, process the result and return the result."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"import {\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n} from '@backstage/catalog-model';\nimport { IncrementalEntityProvider } from '@backstage/plugin-catalog-backend-module-incremental-ingestion';\n\nexport class MyIncrementalEntityProvider\n  implements IncrementalEntityProvider<Cursor, Context>\n{\n  private readonly token: string;\n  private readonly mySource: string;\n\n  constructor(token: string, mySource: string) {\n    this.token = token;\n    this.mySource = mySource;\n  }\n\n  getProviderName() {\n    return `MyIncrementalEntityProvider`;\n  }\n\n  async around(burst: (context: Context) => Promise<void>): Promise<void> {\n    const apiClient = new MyApiClient(this.token);\n\n    await burst({ apiClient });\n  }\n\n  async next(\n    context: Context,\n    cursor: Cursor = { page: 1 },\n  ): Promise<EntityIteratorResult<Cursor>> {\n    const { apiClient } = context;\n    const location = `${this.getProviderName()}:${this.mySource}`;\n\n    // call your API with the current cursor\n    const data = await apiClient.getServices(cursor);\n\n    // calculate the next page\n    const nextPage = page + 1;\n\n    // figure out if there are any more pages to fetch\n    const done = nextPage > data.totalPages;\n\n    // convert returned items into entities\n    const entities = data.items.map(item => ({\n      entity: {\n        apiVersion: 'backstage.io/v1beta1',\n        kind: 'Component',\n        metadata: {\n          name: item.name,\n          annotations: {\n            // You need to define these, otherwise they'll fail validation\n            [ANNOTATION_LOCATION]: location,\n            [ANNOTATION_ORIGIN_LOCATION]: location,\n          },\n        },\n        spec: {\n          type: 'service',\n          lifecycle: 'production', // Ideally your source has this information\n          owner: 'unknown', // Ideally your source has this information\n        },\n      },\n    }));\n\n    // create the next cursor\n    const nextCursor = {\n      page: nextPage,\n    };\n\n    return {\n      done,\n      entities,\n      cursor: nextCursor,\n    };\n  }\n}\n"})}),"\n",(0,a.jsx)(n.p,{children:"Now that you have your new Incremental Entity Provider, we can connect it to the catalog."}),"\n",(0,a.jsx)(n.h3,{id:"installing-the-incremental-entity-provider",children:"Installing the Incremental Entity Provider"}),"\n",(0,a.jsxs)(n.p,{children:["We'll assume you followed the ",(0,a.jsx)(n.a,{href:"#installation",children:"Installation"})," instructions. Now create a module inside ",(0,a.jsx)(n.code,{children:"packages/backend/src/extensions/catalogCustomIncrementalIngestion.ts"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/extensions/catalogCustomIncrementalIngestion.ts"',children:"import {\n  coreServices,\n  createBackendModule,\n} from '@backstage/backend-plugin-api';\nimport { incrementalIngestionProvidersExtensionPoint } from '@backstage/plugin-catalog-backend-module-incremental-ingestion/alpha';\n\nexport const catalogModuleCustomIncrementalIngestionProvider =\n  createBackendModule({\n    pluginId: 'catalog',\n    moduleId: 'custom-incremental-ingestion-provider',\n    register(env) {\n      env.registerInit({\n        deps: {\n          incrementalBuilder: incrementalIngestionProvidersExtensionPoint,\n          config: coreServices.rootConfig,\n        },\n        async init({ incrementalBuilder, config }) {\n          // Assuming the token for the API comes from config\n          const token = config.getString('myApiClient.token');\n          const myEntityProvider = new MyIncrementalEntityProvider(token);\n\n          const options = {\n            // How long should it attempt to read pages from the API in a\n            // single burst? Keep this short. The Incremental Entity Provider\n            // will attempt to read as many pages as it can in this time\n            burstLength: { seconds: 3 },\n\n            // How long should it wait between bursts?\n            burstInterval: { seconds: 3 },\n\n            // How long should it rest before re-ingesting again?\n            restLength: { day: 1 },\n\n            // Optional back-off configuration - how long should it wait to retry\n            // in the event of an error?\n            backoff: [\n              { seconds: 5 },\n              { seconds: 30 },\n              { minutes: 10 },\n              { hours: 3 },\n            ],\n\n            // Optional. Use this to prevent removal of entities above a given\n            // percentage. This can be helpful if a data source is flaky and\n            // sometimes returns a successful status, but fewer than expected\n            // assets to add or maintain in the catalog.\n            rejectRemovalsAbovePercentage: 5,\n\n            // Optional. Similar to rejectRemovalsAbovePercentage, except it\n            // applies to complete, 100% failure of a data source. If true,\n            // a data source that returns a successful status but does not\n            // provide any assets to turn into entities will have its empty\n            // data set rejected.\n            rejectEmptySourceCollections: true,\n          };\n\n          incrementalBuilder.addProvider({\n            provider: myEntityProvider,\n            options,\n          });\n        },\n      });\n    },\n  });\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Add the module to ",(0,a.jsx)(n.code,{children:"packages/backend/src/index.ts"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",metastring:'title="packages/backend/src/index.ts"',children:"/* highlight-add-next-line */\nimport { catalogModuleCustomIncrementalIngestionProvider } from './extensions/catalogCustomIncrementalIngestion';\n\nconst backend = createBackend();\n\nbackend.add(\n  import(\n    '@backstage/plugin-catalog-backend-module-incremental-ingestion/alpha'\n  ),\n);\n\n/* highlight-add-next-line */\nbackend.add(catalogModuleCustomIncrementalIngestionProvider);\n\nbackend.start();\n"})}),"\n",(0,a.jsxs)(n.p,{children:["For a deep dive into the technical details of the Incremental Entity Provider, see ",(0,a.jsx)(n.a,{href:"https://github.com/backstage/backstage/tree/master/plugins/catalog-backend-module-incremental-ingestion",children:"the README"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},221020:(e,n,t)=>{var a=t(296540),o=Symbol.for("react.element"),i=Symbol.for("react.fragment"),s=Object.prototype.hasOwnProperty,r=a.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,c={key:!0,ref:!0,__self:!0,__source:!0};function l(e,n,t){var a,i={},l=null,d=null;for(a in void 0!==t&&(l=""+t),void 0!==n.key&&(l=""+n.key),void 0!==n.ref&&(d=n.ref),n)s.call(n,a)&&!c.hasOwnProperty(a)&&(i[a]=n[a]);if(e&&e.defaultProps)for(a in n=e.defaultProps)void 0===i[a]&&(i[a]=n[a]);return{$$typeof:o,type:e,key:l,ref:d,props:i,_owner:r.current}}n.Fragment=i,n.jsx=l,n.jsxs=l},474848:(e,n,t)=>{e.exports=t(221020)},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var a=t(296540);const o={},i=a.createContext(o);function s(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);