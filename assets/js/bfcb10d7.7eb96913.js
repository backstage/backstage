/*! For license information please see bfcb10d7.7eb96913.js.LICENSE.txt */
"use strict";(self.webpackChunkbackstage_microsite=self.webpackChunkbackstage_microsite||[]).push([[351340],{783764:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>d,toc:()=>l});var a=t(474848),o=t(28453);const i={id:"docker",title:"Building a Docker image",sidebar_label:"Docker",description:"How to build a Backstage Docker image for deployment"},s=void 0,d={id:"deployment/docker",title:"Building a Docker image",description:"How to build a Backstage Docker image for deployment",source:"@site/versioned_docs/version-stable/deployment/docker.md",sourceDirName:"deployment",slug:"/deployment/docker",permalink:"/docs/deployment/docker",draft:!1,unlisted:!1,editUrl:"https://github.com/backstage/backstage/edit/master/docs/deployment/docker.md",tags:[],version:"stable",frontMatter:{id:"docker",title:"Building a Docker image",sidebar_label:"Docker",description:"How to build a Backstage Docker image for deployment"},sidebar:"docs",previous:{title:"Scaling",permalink:"/docs/deployment/scaling"},next:{title:"Kubernetes",permalink:"/docs/deployment/k8s"}},r={},l=[{value:"Summary",id:"summary",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Host Build",id:"host-build",level:2},{value:"Multi-stage Build",id:"multi-stage-build",level:2},{value:"Separate Frontend",id:"separate-frontend",level:2},{value:"Troubleshooting Tips",id:"troubleshooting-tips",level:2},{value:"Community Contributed Dockerfile Alternatives",id:"community-contributed-dockerfile-alternatives",level:2},{value:"Minimal Hardened Image",id:"minimal-hardened-image",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"This section describes how to build a Backstage App into a deployable Docker image. It is split into three sections, first covering the host build approach, which is recommended due to its speed and more efficient and often simpler caching. The second section covers a full multi-stage Docker build, and the last section covers how to deploy the frontend and backend as separate images."}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsxs)(n.p,{children:["This guide assumes your have a basic understanding of Docker and how it works. If you are new to Docker, you can start with the ",(0,a.jsx)(n.a,{href:"https://docs.docker.com/get-started/overview/",children:"Docker overview"})," guide."]}),"\n",(0,a.jsx)(n.p,{children:"You'll also want to complete the following prerequisites:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Created an app following the ",(0,a.jsx)(n.a,{href:"/docs/getting-started/",children:"Getting Started guide"})]}),"\n",(0,a.jsxs)(n.li,{children:["Setup an auth provider, the ",(0,a.jsx)(n.a,{href:"/docs/getting-started/config/authentication",children:"Authentication guide"})," is a good starting point for this, the default ",(0,a.jsx)(n.a,{href:"/docs/auth/guest/provider",children:"Guest auth provider"})," is not intended for use in containerized environments"]}),"\n",(0,a.jsxs)(n.li,{children:["A Postgres database setup that you are able to connect to, the ",(0,a.jsx)(n.a,{href:"/docs/getting-started/config/database",children:"Database guide"})," can help you with this"]}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsxs)(n.p,{children:["Moving forward without addressing these prerequisites is very likely to cause undesirable results, the most common being not having a proper auth provider setup as the default ",(0,a.jsx)(n.a,{href:"/docs/auth/guest/provider",children:"Guest auth provider"})," is not intended for use in containerized environments."]})}),"\n",(0,a.jsx)(n.h2,{id:"host-build",children:"Host Build"}),"\n",(0,a.jsx)(n.p,{children:"This section describes how to build a Docker image from a Backstage repo with\nmost of the build happening outside of Docker. This is almost always the faster\napproach, as the build steps tend to execute faster, and it's possible to have\nmore efficient caching of dependencies on the host, where a single change won't\nbust the entire cache."}),"\n",(0,a.jsxs)(n.p,{children:["The required steps in the host build are to install dependencies with\n",(0,a.jsx)(n.code,{children:"yarn install"}),", generate type definitions using ",(0,a.jsx)(n.code,{children:"yarn tsc"}),", and build the backend\npackage with ",(0,a.jsx)(n.code,{children:"yarn build:backend"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"In a CI workflow it might look something like this, from the root:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"yarn install --immutable\n\n# tsc outputs type definitions to dist-types/ in the repo root, which are then consumed by the build\nyarn tsc\n\n# Build the backend, which bundles it all up into the packages/backend/dist folder.\nyarn build:backend\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Once the host build is complete, we are ready to build our image. The following\n",(0,a.jsx)(n.code,{children:"Dockerfile"})," is included when creating a new app with ",(0,a.jsx)(n.code,{children:"@backstage/create-app"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-dockerfile",children:'FROM node:22-bookworm-slim\n\n# Set Python interpreter for `node-gyp` to use\nENV PYTHON=/usr/bin/python3\n\n# Install isolate-vm dependencies, these are needed by the @backstage/plugin-scaffolder-backend.\nRUN --mount=type=cache,target=/var/cache/apt,sharing=locked \\\n    --mount=type=cache,target=/var/lib/apt,sharing=locked \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends python3 g++ build-essential && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Install sqlite3 dependencies. You can skip this if you don\'t use sqlite3 in the image,\n# in which case you should also move better-sqlite3 to "devDependencies" in package.json.\nRUN --mount=type=cache,target=/var/cache/apt,sharing=locked \\\n    --mount=type=cache,target=/var/lib/apt,sharing=locked \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends libsqlite3-dev && \\\n    rm -rf /var/lib/apt/lists/*\n\n# From here on we use the least-privileged `node` user to run the backend.\nUSER node\n\n# This should create the app dir as `node`.\n# If it is instead created as `root` then the `tar` command below will fail: `can\'t create directory \'packages/\': Permission denied`.\n# If this occurs, then ensure BuildKit is enabled (`DOCKER_BUILDKIT=1`) so the app dir is correctly created as `node`.\nWORKDIR /app\n\n# Copy files needed by Yarn\nCOPY --chown=node:node .yarn ./.yarn\nCOPY --chown=node:node .yarnrc.yml ./\nCOPY --chown=node:node backstage.json ./\n\n# This switches many Node.js dependencies to production mode.\nENV NODE_ENV=production\n\n# This disables node snapshot for Node 20 to work with the Scaffolder\nENV NODE_OPTIONS="--no-node-snapshot"\n\n# Copy repo skeleton first, to avoid unnecessary docker cache invalidation.\n# The skeleton contains the package.json of each package in the monorepo,\n# and along with yarn.lock and the root package.json, that\'s enough to run yarn install.\nCOPY --chown=node:node yarn.lock package.json packages/backend/dist/skeleton.tar.gz ./\nRUN tar xzf skeleton.tar.gz && rm skeleton.tar.gz\n\nRUN --mount=type=cache,target=/home/node/.cache/yarn,sharing=locked,uid=1000,gid=1000 \\\n    yarn workspaces focus --all --production && rm -rf "$(yarn cache clean)"\n\n# This will include the examples, if you don\'t need these simply remove this line\nCOPY --chown=node:node examples ./examples\n\n# Then copy the rest of the backend bundle, along with any other files we might want.\nCOPY --chown=node:node packages/backend/dist/bundle.tar.gz app-config*.yaml ./\nRUN tar xzf bundle.tar.gz && rm bundle.tar.gz\n\nCMD ["node", "packages/backend", "--config", "app-config.yaml", "--config", "app-config.production.yaml"]\n'})}),"\n",(0,a.jsxs)(n.p,{children:["For more details on how the ",(0,a.jsx)(n.code,{children:"backend:bundle"})," command and the ",(0,a.jsx)(n.code,{children:"skeleton.tar.gz"}),"\nfile works, see the\n",(0,a.jsxs)(n.a,{href:"/docs/tooling/cli/commands#backendbundle",children:[(0,a.jsx)(n.code,{children:"backend:bundle"})," command docs"]}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"Dockerfile"})," is located at ",(0,a.jsx)(n.code,{children:"packages/backend/Dockerfile"}),", but needs to be\nexecuted with the root of the repo as the build context, in order to get access\nto the root ",(0,a.jsx)(n.code,{children:"yarn.lock"})," and ",(0,a.jsx)(n.code,{children:"package.json"}),", along with any other files that\nmight be needed, such as ",(0,a.jsx)(n.code,{children:".npmrc"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"@backstage/create-app"})," command adds the following ",(0,a.jsx)(n.code,{children:".dockerignore"})," in the\nroot of the repo to speed up the build by reducing build context size:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:".git\n.yarn/cache\n.yarn/install-state.gz\nnode_modules\npackages/*/src\npackages/*/node_modules\nplugins\n*.local.yaml\n"})}),"\n",(0,a.jsxs)(n.p,{children:["With the project built and the ",(0,a.jsx)(n.code,{children:".dockerignore"})," and ",(0,a.jsx)(n.code,{children:"Dockerfile"})," in place, we are\nnow ready to build the final image. From the root of the repo, execute the\nbuild:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker image build . -f packages/backend/Dockerfile --tag backstage\n"})}),"\n",(0,a.jsx)(n.p,{children:"To try out the image locally you can run the following:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"docker run -it -p 7007:7007 backstage\n"})}),"\n",(0,a.jsxs)(n.p,{children:["You should then start to get logs in your terminal, and then you can open your\nbrowser at ",(0,a.jsx)(n.code,{children:"http://localhost:7007"})]}),"\n",(0,a.jsx)(n.h2,{id:"multi-stage-build",children:"Multi-stage Build"}),"\n",(0,a.jsx)(n.admonition,{title:"Note",type:"note",children:(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:".dockerignore"})," is different in this setup, read on for more\ndetails."]})}),"\n",(0,a.jsx)(n.p,{children:"This section describes how to set up a multi-stage Docker build that builds the\nentire project within Docker. This is typically slower than a host build, but is\nsometimes desired because Docker in Docker is not available in the build\nenvironment, or due to other requirements."}),"\n",(0,a.jsxs)(n.p,{children:["The build is split into three different stages, where the first stage finds all\nof the ",(0,a.jsx)(n.code,{children:"package.json"})," files that are relevant for the initial install step\nenabling us to cache the initial ",(0,a.jsx)(n.code,{children:"yarn install"})," that installs all dependencies.\nThe second stage executes the build itself, and is similar to the steps we\nexecute on the host in the host build. The third and final stage then packages\nit all together into the final image, and is similar to the ",(0,a.jsx)(n.code,{children:"Dockerfile"})," of the\nhost build."]}),"\n",(0,a.jsxs)(n.p,{children:["The following ",(0,a.jsx)(n.code,{children:"Dockerfile"})," executes the multi-stage build and should be added to\nthe repo root:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-dockerfile",children:'# Stage 1 - Create yarn install skeleton layer\nFROM node:22-bookworm-slim AS packages\n\nWORKDIR /app\nCOPY backstage.json package.json yarn.lock ./\nCOPY .yarn ./.yarn\nCOPY .yarnrc.yml ./\n\nCOPY packages packages\n\n# Comment this out if you don\'t have any internal plugins\nCOPY plugins plugins\n\nRUN find packages \\! -name "package.json" -mindepth 2 -maxdepth 2 -exec rm -rf {} \\+\n\n# Stage 2 - Install dependencies and build packages\nFROM node:22-bookworm-slim AS build\n\n# Set Python interpreter for `node-gyp` to use\nENV PYTHON=/usr/bin/python3\n\n# Install isolate-vm dependencies, these are needed by the @backstage/plugin-scaffolder-backend.\nRUN --mount=type=cache,target=/var/cache/apt,sharing=locked \\\n    --mount=type=cache,target=/var/lib/apt,sharing=locked \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends python3 g++ build-essential && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Install sqlite3 dependencies. You can skip this if you don\'t use sqlite3 in the image,\n# in which case you should also move better-sqlite3 to "devDependencies" in package.json.\nRUN --mount=type=cache,target=/var/cache/apt,sharing=locked \\\n    --mount=type=cache,target=/var/lib/apt,sharing=locked \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends libsqlite3-dev && \\\n    rm -rf /var/lib/apt/lists/*\n\nUSER node\nWORKDIR /app\n\nCOPY --from=packages --chown=node:node /app .\n\nRUN --mount=type=cache,target=/home/node/.cache/yarn,sharing=locked,uid=1000,gid=1000 \\\n    yarn install --immutable\n\nCOPY --chown=node:node . .\n\nRUN yarn tsc\nRUN yarn --cwd packages/backend build\n\nRUN mkdir packages/backend/dist/skeleton packages/backend/dist/bundle \\\n    && tar xzf packages/backend/dist/skeleton.tar.gz -C packages/backend/dist/skeleton \\\n    && tar xzf packages/backend/dist/bundle.tar.gz -C packages/backend/dist/bundle\n\n# Stage 3 - Build the actual backend image and install production dependencies\nFROM node:22-bookworm-slim\n\n# Set Python interpreter for `node-gyp` to use\nENV PYTHON=/usr/bin/python3\n\n# Install isolate-vm dependencies, these are needed by the @backstage/plugin-scaffolder-backend.\nRUN --mount=type=cache,target=/var/cache/apt,sharing=locked \\\n    --mount=type=cache,target=/var/lib/apt,sharing=locked \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends python3 g++ build-essential && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Install sqlite3 dependencies. You can skip this if you don\'t use sqlite3 in the image,\n# in which case you should also move better-sqlite3 to "devDependencies" in package.json.\nRUN --mount=type=cache,target=/var/cache/apt,sharing=locked \\\n    --mount=type=cache,target=/var/lib/apt,sharing=locked \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends libsqlite3-dev && \\\n    rm -rf /var/lib/apt/lists/*\n\n# From here on we use the least-privileged `node` user to run the backend.\nUSER node\n\n# This should create the app dir as `node`.\n# If it is instead created as `root` then the `tar` command below will\n# fail: `can\'t create directory \'packages/\': Permission denied`.\n# If this occurs, then ensure BuildKit is enabled (`DOCKER_BUILDKIT=1`)\n# so the app dir is correctly created as `node`.\nWORKDIR /app\n\n# Copy the install dependencies from the build stage and context\nCOPY --from=build --chown=node:node /app/.yarn ./.yarn\nCOPY --from=build --chown=node:node /app/.yarnrc.yml  ./\nCOPY --from=build --chown=node:node /app/backstage.json ./\nCOPY --from=build --chown=node:node /app/yarn.lock /app/package.json /app/packages/backend/dist/skeleton/ ./\n\n# Note: The skeleton bundle only includes package.json files -- if your app has\n# plugins that define a `bin` export, the bin files need to be copied as well to\n# be linked in node_modules/.bin during yarn install.\n\nRUN --mount=type=cache,target=/home/node/.cache/yarn,sharing=locked,uid=1000,gid=1000 \\\n    yarn workspaces focus --all --production && rm -rf "$(yarn cache clean)"\n\n# Copy the built packages from the build stage\nCOPY --from=build --chown=node:node /app/packages/backend/dist/bundle/ ./\n\n# Copy any other files that we need at runtime\nCOPY --chown=node:node app-config*.yaml ./\n\n# This will include the examples, if you don\'t need these simply remove this line\nCOPY --chown=node:node examples ./examples\n\n# This switches many Node.js dependencies to production mode.\nENV NODE_ENV=production\n\n# This disables node snapshot for Node 20 to work with the Scaffolder\nENV NODE_OPTIONS="--no-node-snapshot"\n\nCMD ["node", "packages/backend", "--config", "app-config.yaml", "--config", "app-config.production.yaml"]\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Note that a newly created Backstage app will typically not have a ",(0,a.jsx)(n.code,{children:"plugins/"}),"\nfolder, so you will want to comment that line out. This build also does not work\nin the main repo, since the ",(0,a.jsx)(n.code,{children:"backstage-cli"})," which is used for the build doesn't\nend up being properly installed."]}),"\n",(0,a.jsxs)(n.p,{children:["To speed up the build when not running in a fresh clone of the repo you should\nset up a ",(0,a.jsx)(n.code,{children:".dockerignore"}),". This one is different than the host build one, because\nwe want to have access to the source code of all packages for the build. We can\nhowever ignore any existing build output or dependencies on the host. For our\nnew ",(0,a.jsx)(n.code,{children:".dockerignore"}),", replace the contents of your existing one with this:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-text",children:"dist-types\nnode_modules\npackages/*/dist\npackages/*/node_modules\nplugins/*/dist\nplugins/*/node_modules\n*.local.yaml\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Once you have added both the ",(0,a.jsx)(n.code,{children:"Dockerfile"})," and ",(0,a.jsx)(n.code,{children:".dockerignore"})," to the root of\nyour project, run the following to build the container under a specified tag."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"docker image build -t backstage .\n"})}),"\n",(0,a.jsx)(n.p,{children:"To try out the image locally you can run the following:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"docker run -it -p 7007:7007 backstage\n"})}),"\n",(0,a.jsxs)(n.p,{children:["You should then start to get logs in your terminal, and then you can open your\nbrowser at ",(0,a.jsx)(n.code,{children:"http://localhost:7007"})]}),"\n",(0,a.jsx)(n.h2,{id:"separate-frontend",children:"Separate Frontend"}),"\n",(0,a.jsx)(n.admonition,{title:"Note",type:"note",children:(0,a.jsxs)(n.p,{children:["This is an optional step, and you will lose out on the features of the\n",(0,a.jsx)(n.code,{children:"@backstage/plugin-app-backend"})," plugin. Most notably the frontend configuration\nwill no longer be injected by the backend, you will instead need to use the\ncorrect configuration when building the frontend bundle."]})}),"\n",(0,a.jsxs)(n.p,{children:["It is sometimes desirable to serve the frontend separately from the backend,\neither from a separate image or for example a static file serving provider. The\nfirst step in doing so is to remove the ",(0,a.jsx)(n.code,{children:"app-backend"})," plugin from the backend\npackage, which is done as follows:"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Delete ",(0,a.jsx)(n.code,{children:"packages/backend/src/plugins/app.ts"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Remove the following line from ",(0,a.jsx)(n.code,{children:"packages/backend/src/index.ts"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ts",children:"backend.add(import('@backstage/plugin-app-backend'));\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:["Remove the ",(0,a.jsx)(n.code,{children:"@backstage/plugin-app-backend"})," and the app package dependency\n(e.g. ",(0,a.jsx)(n.code,{children:"app"}),") from ",(0,a.jsx)(n.code,{children:"packages/backend/package.json"}),". If you don't remove the\napp package dependency the app will still be built and bundled with the\nbackend."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Once the ",(0,a.jsx)(n.code,{children:"app-backend"})," is removed from the backend, you can use your favorite\nstatic file serving method for serving the frontend. An example of how to set up\nan NGINX image is available in the\n",(0,a.jsx)(n.a,{href:"https://github.com/backstage/backstage/blob/master/contrib/docker/frontend-with-nginx",children:"contrib folder in the main repo"})]}),"\n",(0,a.jsxs)(n.p,{children:["Note that if you're building a separate docker build of the frontend you\nprobably need to adjust ",(0,a.jsx)(n.code,{children:".dockerignore"})," appropriately. Most likely by making\nsure ",(0,a.jsx)(n.code,{children:"packages/app/dist"})," is not ignored."]}),"\n",(0,a.jsx)(n.h2,{id:"troubleshooting-tips",children:"Troubleshooting Tips"}),"\n",(0,a.jsx)(n.p,{children:"When building Docker images you may run into problems from time to time, there are two handy flags you can use to help:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"--progress=plain"}),": this will give you a more verbose output and not fold the logs into sections. This is very useful when have an error but it just shows you the last command and possibly an exit code. Using this flag you are more likely to see where the error actually is."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"--no-cache"}),": this will rebuild all the layers every time. This is helpful when you want to be sure that it's building from scratch."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Here's an example of these flags in use:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"docker image build . -f packages/backend/Dockerfile --tag backstage --progress=plain --no-cache\n"})}),"\n",(0,a.jsx)(n.h2,{id:"community-contributed-dockerfile-alternatives",children:"Community Contributed Dockerfile Alternatives"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"Dockerfile"})," mentioned above located in ",(0,a.jsx)(n.code,{children:"packages/backend"})," is maintained by the maintainers of Backstage, however there are also community contributed Dockerfile alternatives located in ",(0,a.jsx)(n.code,{children:"contrib/docker"}),". The ",(0,a.jsx)(n.code,{children:"Dockerfile"}),"s in ",(0,a.jsx)(n.code,{children:"contrib/docker"})," are not maintained by the maintainers of Backstage and are not necessarily updated when the ",(0,a.jsx)(n.code,{children:"Dockerfile"})," located in ",(0,a.jsx)(n.code,{children:"packages/backend"})," is updated."]}),"\n",(0,a.jsx)(n.h3,{id:"minimal-hardened-image",children:"Minimal Hardened Image"}),"\n",(0,a.jsxs)(n.p,{children:["A contributed ",(0,a.jsx)(n.code,{children:"Dockerfile"})," exists within the directory of ",(0,a.jsx)(n.code,{children:"contrib/docker/minimal-hardened-image"})," which uses the ",(0,a.jsx)(n.a,{href:"https://github.com/wolfi-dev",children:(0,a.jsx)(n.code,{children:"wolfi-base"})})," image to reduce vulnerabilities. When this was contributed, this alternative ",(0,a.jsx)(n.code,{children:"Dockerfile"})," reduced 98.2% of vulnerabilities in the built Backstage docker image when compared with the image built from ",(0,a.jsx)(n.code,{children:"packages/backend/Dockerfile"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["To reduce maintenance, the digest of the image has been removed from the ",(0,a.jsx)(n.code,{children:"contrib/docker/minimal-hardened-image/Dockerfile"})," file. A complete example with the digest would be ",(0,a.jsx)(n.code,{children:"cgr.dev/chainguard/wolfi-base:latest@sha256:3d6dece13cdb5546cd03b20e14f9af354bc1a56ab5a7b47dca3e6c1557211fcf"})," and it is suggested to update the ",(0,a.jsx)(n.code,{children:"FROM"})," line in the ",(0,a.jsx)(n.code,{children:"Dockerfile"})," to use a digest. Please do a docker pull on the image to get the latest digest. Using the digest allows tools such as Dependabot or Renovate to know exactly which image digest is being utilized and allows for Pull Requests to be triggered when a new digest is available."]}),"\n",(0,a.jsx)(n.p,{children:"It is suggested to setup Dependabot/Renovate or a similar tool to ensure the image is kept up to date so that vulnerability fixes that have been addressed are pulled in frequently."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},221020:(e,n,t)=>{var a=t(296540),o=Symbol.for("react.element"),i=Symbol.for("react.fragment"),s=Object.prototype.hasOwnProperty,d=a.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,r={key:!0,ref:!0,__self:!0,__source:!0};function l(e,n,t){var a,i={},l=null,c=null;for(a in void 0!==t&&(l=""+t),void 0!==n.key&&(l=""+n.key),void 0!==n.ref&&(c=n.ref),n)s.call(n,a)&&!r.hasOwnProperty(a)&&(i[a]=n[a]);if(e&&e.defaultProps)for(a in n=e.defaultProps)void 0===i[a]&&(i[a]=n[a]);return{$$typeof:o,type:e,key:l,ref:c,props:i,_owner:d.current}}n.Fragment=i,n.jsx=l,n.jsxs=l},474848:(e,n,t)=>{e.exports=t(221020)},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>d});var a=t(296540);const o={},i=a.createContext(o);function s(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);